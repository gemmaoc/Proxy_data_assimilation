"""
 This script computes climate indices from the posterior.  
 Calculations are done on the "subsampled" files.
    author: Michael P. Erb
    date  : 1/23/2018

 Revisions
 ** Andre Perkins (UW) 8/3/2018
    - Removed dependencies on xarray and eofs and instead use netCDF4 and
      scipy.linalg.svd to load data and calculate eofs
    - Moved index functions from calculate_climate_indices into this script
      so that it's self contained
    - Cleaned up formatting for clairty and some move towards PEP8 compliance
    - Simplified some of the numpy usage for weighted means, anomaly
      calculations, and standardization
    - Changed the PDO calculation to find the pattern on the grand ensemble
      mean and then use that pattern to determine an index for each ensemble
      member.  Still assumes that the first ensemble mean EOF is the PDO.
 
 ** Robert Tardif (UW) - Sept. 2019
    - More flexible capabilities, now with the possibility of reading in the 
      data generated by LMR at runtime, contained in .npz output files. 
      Also additional possibility of calculating the indices on *all* ensemble
      members if the output data is available. (For now: this is only possible
      with the .npz data used as input). 
      Note: original code only offered the use of data from post-processed netcdf 
            files and dealt only with a subsample of ensemble members.
      A number of sanity checks have also been added to notify the user of possible 
      dataset inconsistencies. 
    - Added the calculation of the NAO index (station-based version of the calculation)
    - Added the calculation of the SAM index (station-based version of the calculation)
    - Added the calculation of the AO index (using mean sea-level pressure recon. data)

 *Important note*: calculation of the AMO and PDO assumes SST recon data is available
                   on a regular lat-lon grid! 

 TODO - Code needs additional flexibility: 
        - Should be able to run and calculate SST-based indices when MSLP recons are
          not available, and vice-versa
        - Handling of recon data for which only ensemble means are available?
        - Vectorized calculations to speed up the code. 
        - Additional indices: PC-based NAO, etc.
        - Calculation and ouput of indices obtained from the prior ensemble

"""

import numpy as np
import numpy.ma as ma
import os, glob
from netCDF4 import Dataset
from scipy.linalg import svd

def main():

    # --- --- --- required user input parameters --- --- ---

    #data_dir = '/home/disk/enkf3/rtardif/LMR/output/productionFinal_V1_Summer2018'
    data_dir = '/home/disk/kalman3/rtardif/LMR/output'

    # calculation of indices require spatial reconstructions of SST (tos)
    # and MSLP (psl) variables. Name(s) of experiment(s) with these data
    # sets have to be specified here.
    # -------------------------------------------------------------------
    #experiment_name = 'productionFinal_gisgpcc_ccms4_LMRdbv1.0.0: LMR production v2.0'
    #experiment_name_sst  = 'productionFinal_gisgpcc_ccms4_LMRdbv0.4.0_tos'
    #experiment_name_mslp = 'productionFinal_gisgpcc_ccms4_LMRdbv0.4.0_psl'
    ## directory where the output files will be generated
    #output_dir = '/home/disk/enkf3/rtardif/LMR/output/productionFinal_V1_Summer2018/productionFinal_gisgpcc_ccms4_LMRdbv0.4.0_ClimateIndices'
    # ---
    experiment_name = 'productionFinal2_gisgpcc_ccms4_LMRdbv1.1.0: LMR production v2.1'
    experiment_name_sst  = 'productionFinal2_gisgpcc_ccms4_LMRdbv1.1.0_tos'
    experiment_name_mslp = 'productionFinal2_gisgpcc_ccms4_LMRdbv1.1.0_psl'
    # directory where the output files will be generated
    output_dir = '/home/disk/kalman3/rtardif/LMR/output/productionFinal2_gisgpcc_ccms4_LMRdbv1.1.0_ClimateIndices'

    # Input taken from which LMR output? Post-processed netcdf files or original npz files? 
    input_stream = 'npz'            # 'npz' or 'netcdf'
    input_type   = 'ensemble_full'  # 'ensemble_full' or 'ensemble_subsample'

    # --- --- --- required user input parameters --- --- ---

    
    # create output directory if it does not already exist
    if not os.path.exists(output_dir):
        os.system('mkdir %s' %(output_dir))
    
    
    # LOAD DATA ----------------------------------------------------------------

    if input_stream == 'npz':
        # sst
        experiment_sst = os.path.join(data_dir, experiment_name_sst)
        sst_MCruns = glob.glob(experiment_sst+'/r*')
        
        # mslp
        experiment_psl = os.path.join(data_dir, experiment_name_mslp)
        psl_MCruns = glob.glob(experiment_psl+'/r*')

        # check whether the necessary input data is available
        # look into the first "r" directory
        sst_filename = sst_MCruns[0]+'/'+input_type+'_tos_sfc_Omon.npz'
        psl_filename = psl_MCruns[0]+'/'+input_type+'_psl_sfc_Amon.npz'
        if not os.path.exists(sst_filename) or not os.path.exists(psl_filename):
            raise SystemExit('One or more required %s .npz data file is not found. '
                             'Cannot proceed. Exiting.'%input_type)

        # get the necessary dimensions
        nbMCruns_sst = len(sst_MCruns)
        nbMCruns_psl = len(psl_MCruns)
        if nbMCruns_sst != nbMCruns_psl:
            raise SystemExit('Not the same number of MC relizations in SST and MSLP data! '
                             'Cannot proceed. Exiting.')

        
        # Monte-Carlo realizations
        niter = len(sst_MCruns)

        # get ensemble size
        fh_sst = np.load(sst_MCruns[0]+'/'+input_type+'_tos_sfc_Omon.npz')
        nens = fh_sst['nens']

        # years in the reconstructions
        # stored as an array of strings (!)
        years_str =  fh_sst['years']
        # convert to array of floats
        years = np.asarray([float(item) for item in years_str])
        nyears, = years.shape
        print('(nyears, niter, nens)=', nyears, niter, nens)
        time_days = years*365. # time in nb of days (no leap years)
        
        for iteration in range(niter):

            if iteration == 0:
                # declare output arrays with right dimensions
                pdo = np.empty((nyears, niter, nens)) * np.nan
                amo = np.empty((nyears, niter, nens)) * np.nan
                nino34 = np.empty((nyears, niter, nens)) * np.nan
                ao = np.empty((nyears, niter, nens)) * np.nan
                nao = np.empty((nyears, niter, nens)) * np.nan
                soi = np.empty((nyears, niter, nens)) * np.nan
                sam = np.empty((nyears, niter, nens)) * np.nan
                
                # get lats/lons
                fh_sst = np.load(sst_MCruns[iteration]+'/'+input_type+'_tos_sfc_Omon.npz')
                lat = fh_sst['lat']
                lon = fh_sst['lon']
                nlat = fh_sst['nlat']
                nlon = fh_sst['nlon']
                sst_mean = np.empty((niter, nyears, nlat, nlon)) * np.nan
                
                # PDO calculation on "grand" ensemble mean
                # 1- get grand ensemble mean from ensemble mean output from all MC runs
                #    (always available)
                irun = 0
                for MCrun in sst_MCruns:
                    fh_sst_mean = np.load(MCrun+'/ensemble_mean_tos_sfc_Omon.npz')
                    sst_mean[irun,:] = fh_sst_mean['xam']
                    irun +=1
                    
                sst_grand_mean = np.mean(sst_mean,axis=0)
                del sst_mean

                #print('==>', sst_grand_mean.shape)
                #print(lat.shape)
    
                # 2- Call calculate_pdo and save output
                # ... hack ...
                if len(lat.shape) > 1:
                    lat1d = lat[:,0]
                    lon1d = lon[0,:]
                else:
                    lat1d = lat
                    lon1d = lon
                    
                [ensmean_pdo_patt, ensmean_pdo_idx,
                 lat_npac, lon_npac] = calculate_pdo(sst_grand_mean, lat1d, lon1d)

                pdo_pat_out = os.path.join(output_dir,
                               'ensmean_pdo_pattern_index.npz')
                np.savez(pdo_pat_out, pdo_pattern=ensmean_pdo_patt,
                         pdo_idx=ensmean_pdo_idx, lat_npac=lat_npac, lon_npac=lon_npac)
                
                
            # get SST data for current MC realization
            iternumber = int(sst_MCruns[iteration].split('/')[-1].lstrip('r'))
            fh_sst = np.load(sst_MCruns[iteration]+'/'+input_type+'_tos_sfc_Omon.npz')
            #print(fh_sst.files)
            print('\nUploading SST data...')
            sst_array = fh_sst['xa_ens']
            print('sst:', sst_array.shape)
            
            # making sure data from the corresponding MSLP MC run is read
            print('Uploading MSLP data...')
            psl_MCrun = experiment_psl+'/r'+str(iternumber)
            fh_psl = np.load(psl_MCrun+'/'+input_type+'_psl_sfc_Amon.npz')
            psl_array = fh_psl['xa_ens']
            print('psl:',psl_array.shape)
            
            for ens_member in range(nens):
                print('\n === Calculating climate indices.  Iteration: ' +
                      str(iteration+1) + '/' + str(niter) +
                      ',  ensemble member: ' + str(ens_member+1) +
                      '/' + str(nens) + ' ===')
                
                # --- PDO ---
                curr_pdo_idx = calculate_pdo_index(ensmean_pdo_patt,
                                                   sst_array[:,:,:,ens_member],
                                                   lat1d, lon1d)
                pdo[:, iternumber, ens_member] = curr_pdo_idx
                
                # --- AMO ---
                curr_amo = calculate_amo(sst_array[:,:,:,ens_member],
                                         lat1d, lon1d)
                amo[:, iternumber, ens_member] = curr_amo

                # --- NINO34 ---
                curr_nino34 = calculate_nino34(sst_array[:,:,:,ens_member],
                                               lat1d, lon1d)
                nino34[:, iternumber, ens_member] = curr_nino34

                # --- AO ---
                curr_ao = calculate_ao_zonal_means(psl_array[:,:,:,ens_member],
                                                   lat1d, lon1d, years)
                ao[:, iternumber, ens_member] = curr_ao
                
                # --- NAO ---
                curr_nao = calculate_nao_stations(psl_array[:,:,:,ens_member],
                                                  lat1d, lon1d, years)
                nao[:, iternumber, ens_member] = curr_nao

                # --- SOI ---
                curr_soi = calculate_soi(psl_array[:,:,:,ens_member],
                                         lat1d, lon1d, years)
                soi[:, iternumber, ens_member] = curr_soi

                # --- SAM ---
                curr_sam = calculate_sam(psl_array[:,:,:,ens_member],
                                         lat1d, lon1d, years)
                sam[:, iternumber, ens_member] = curr_sam
                
                
                
        
    elif input_stream == 'netcdf':


        # ... this needs to be updated ... to much hardcoding ... - RT 09/19
        
        experiment_sst = os.path.join(data_dir, experiment_name_sst,
                                      'sst_MCruns_ensemble_subsample.nc')
        sst_ncf = Dataset(experiment_sst, 'r')
        sst_all = sst_ncf.variables['sst']
        lon = sst_ncf.variables['lon'][:]
        lat = sst_ncf.variables['lat'][:]
        time_days = sst_ncf['time'][:]

        # Load Ensemble Mean and take average over MC-iterations for PDO calc
        exp_sst_ensmean = os.path.join(data_dir, experiment_name_sst,
                                       'sst_MCruns_ensemble_mean.nc')
        with Dataset(exp_sst_ensmean, 'r') as sst_ensmean_ncf:
            sst_grand_mean = sst_ensmean_ncf.variables['sst'][:].mean(axis=1)

        # ...
        experiment_psl = os.path.join(data_dir, experiment_name_mslp,
                                      'prmsl_MCruns_ensemble_subsample.nc')

        psl_ncf = Dataset(experiment_psl, 'r')
        psl_all = psl_ncf.variables['prmsl']

        # ...
        years = time_days/365
        years = years.astype(int)

        nyears = years.shape[0]
        niter = sst_all.shape[1]
        nens = sst_all.shape[4]

        # Initialize nan arrays
        pdo = np.empty((nyears, niter, nens)) * np.nan
        amo = np.empty((nyears, niter, nens)) * np.nan
        nino34 = np.empty((nyears, niter, nens)) * np.nan
        ao = np.empty((nyears, niter, nens)) * np.nan
        nao = np.empty((nyears, niter, nens)) * np.nan
        soi = np.empty((nyears, niter, nens)) * np.nan
        sam = np.empty((nyears, niter, nens)) * np.nan
        
        [ensmean_pdo_patt,
         ensmean_pdo_idx,
         lat_npac,
         lon_npac] = calculate_pdo(sst_grand_mean, lat, lon)

        pdo_pat_out = os.path.join(output_dir,
                                   'ensmean_pdo_pattern_index.npz')
        np.savez(pdo_pat_out, pdo_pattern=ensmean_pdo_patt,
                 pdo_idx=ensmean_pdo_idx, lat_npac=lat_npac, lon_npac=lon_npac)

        for iteration in range(niter):
            for ens_member in range(nens):
                print('\n === Calculating climate indices.  Iteration: ' +
                      str(iteration+1) + '/' + str(niter) +
                      ',  Ensemble member: ' + str(ens_member+1) +
                      '/' + str(nens) + ' ===')

                curr_sst = sst_all[:, iteration, :, :, ens_member]
                curr_psl = psl_all[:, iteration, :, :, ens_member]

                curr_pdo_idx = calculate_pdo_index(ensmean_pdo_patt,
                                                   curr_sst, lat, lon)
                pdo[:, iteration, ens_member] = curr_pdo_idx

                curr_nino34 = calculate_nino34(curr_sst, lat, lon)
                nino34[:, iteration, ens_member] = curr_nino34

                curr_amo = calculate_amo(curr_sst, lat, lon)
                amo[:, iteration, ens_member] = curr_amo

                curr_ao = calculate_ao_zonal_means(curr_psl,
                                                   lat, lon, years)
                ao[:, iternumber, ens_member] = curr_ao

                curr_nao = calculate_nao_stations(curr_psl, lat, lon, years)
                nao[:, iteration, ens_member] = curr_nao

                curr_soi = calculate_soi(curr_psl, lat, lon, years)
                soi[:, iteration, ens_member] = curr_soi

                curr_sam = calculate_sam(curr_psl,
                                         lat, lon, years)
                sam[:, iternumber, ens_member] = curr_sam
                
                
        sst_ncf.close()
        psl_ncf.close()

        
    else:
        raise SystemExit('Unrecognized input_stream input parameter. Exiting!')

    
    
    # OUTPUT THE DATA TO A FILE ------------------------------------------------

    missing_val = np.nan
    
    # Create the netcdf file for the current variable
    outfile_nc = 'posterior_climate_indices_MCruns_'+input_type+'.nc'
    outpath = os.path.join(output_dir, outfile_nc)
    outfile = Dataset(outpath, 'w', format='NETCDF4')
    outfile.description = 'Climate indices calculated from an LMR reconstruction'
    outfile.experiment = experiment_name
    outfile.comment = 'File contains values for each Monte-Carlo realization (MCrun)'

    # define dimensions
    outfile.createDimension('time', nyears)
    outfile.createDimension('MCrun', niter)
    outfile.createDimension('members', nens)
    outfile.createDimension('lat_npac', len(lat_npac))
    outfile.createDimension('lon_npac', len(lon_npac))

    # define variables & upload the data to file
    # --- time ---
    time = outfile.createVariable('time', 'i', ('time',))
    time.description = 'time'
    time.long_name = 'Time'
    time.standard_name = 'time'
    time.units = 'days since 0000-01-01 00:00:00'
    time.calendar = 'noleap'
    time.actual_range = np.array((np.min(time_days), np.max(time_days)))
    
    # --- PDO and related variables ---
    varout_ensmean_pdo_patt = outfile.createVariable('ensmean_pdo_pattern','f',
                                                     ('lat_npac', 'lon_npac'),
                                                     fill_value=missing_val)
    varout_ensmean_pdo_patt.description = 'ensmean_pdo_pattern'
    varout_ensmean_pdo_patt.long_name = ('Ensemble Mean Pacific Decadal '
                                         'Oscillation Pattern')
    varout_ensmean_pdo_patt.units = ''
    varout_ensmean_pdo_patt.level = 'sfc'
    varout_ensmean_pdo_patt.missing_value = missing_val

    varout_ensmean_pdo_idx = outfile.createVariable('ensmean_pdo_idx',
                                                    'f', ('time',))
    varout_ensmean_pdo_idx.description = ('PDO index calculated on the grand '
                                          'ensemble mean (average of mc_iter '
                                          'and ensemble members)')
    varout_ensmean_pdo_idx.long_name = ('Ensemble Mean Pacific Decadal '
                                        'Oscillation Index')
    varout_ensmean_pdo_idx.units = ''
    varout_ensmean_pdo_idx.level = 'sfc'

    varout_lat_npac = outfile.createVariable('lat_npac', 'f', ('lat_npac',))
    varout_lat_npac.description = 'North Pacific latitudes for PDO Pattern'
    varout_lat_npac.long_name = 'North Pacific latitudes'
    varout_lat_npac.units = 'Degrees latitude'

    varout_lon_npac = outfile.createVariable('lon_npac', 'f', ('lon_npac',))
    varout_lon_npac.description = 'North Pacific longitudes for PDO Pattern'
    varout_lon_npac.long_name = 'North Pacific longitudes'
    varout_lon_npac.units = 'Degrees longitude'

    varout_pdo = outfile.createVariable('pdo', 'f', ('time','MCrun','members'))
    varout_pdo.description = 'pdo'
    varout_pdo.long_name = 'Pacific Decadal Oscillation Index'
    varout_pdo.units = ''
    varout_pdo.level = 'sfc'
    
    # --- AMO ---
    varout_amo = outfile.createVariable('amo', 'f', ('time','MCrun','members'))
    varout_amo.description = 'amo'
    varout_amo.long_name = 'Atlantic Multidecadal Oscillation Index'
    varout_amo.units = ''
    varout_amo.level = 'sfc'
    
    # --- NINO3.4 ---
    varout_nino34 = outfile.createVariable('nino34', 'f', ('time','MCrun','members'))
    varout_nino34.description = 'nino34'
    varout_nino34.long_name = 'Nino3.4 Index'
    varout_nino34.units = ''
    varout_nino34.level = 'sfc'

    # --- AO ---
    varout_ao = outfile.createVariable('ao', 'f', ('time','MCrun','members'))
    varout_ao.description = 'ao'
    varout_ao.long_name = 'Arctic Oscillation Index'
    varout_ao.units = ''
    varout_ao.level = 'sfc'
    
    # --- NAO ---
    varout_nao = outfile.createVariable('nao', 'f', ('time','MCrun','members'))
    varout_nao.description = 'nao'
    varout_nao.long_name = 'North Atlantic Oscillation Index'
    varout_nao.units = ''
    varout_nao.level = 'sfc'
    
    # --- SOI ---
    varout_soi = outfile.createVariable('soi', 'f', ('time','MCrun','members'))
    varout_soi.description = 'soi'
    varout_soi.long_name = 'Southern Oscillation Index'
    varout_soi.units = ''
    varout_soi.level = 'sfc'

    # --- SAM ---
    varout_sam = outfile.createVariable('sam', 'f', ('time','MCrun','members'))
    varout_sam.description = 'sam'
    varout_sam.long_name = 'Southern Annular Mode Index'
    varout_sam.units = ''
    varout_sam.level = 'sfc'


    
    # upload the data to file
    time[:]          = time_days
    varout_amo[:]    = amo
    varout_pdo[:]    = pdo
    varout_ensmean_pdo_patt[:] = ensmean_pdo_patt
    varout_ensmean_pdo_idx[:] = ensmean_pdo_idx
    varout_lat_npac[:] = lat_npac
    varout_lon_npac[:] = lon_npac
    varout_nino34[:] = nino34
    varout_ao[:]     = ao
    varout_nao[:]    = nao
    varout_soi[:]    = soi
    varout_sam[:]    = sam
    
    # Closing the file
    outfile.close()


# -----------------------------------------------------------------------------
# --------------------------------- functions ---------------------------------
    
# This function takes a time-lat-lon variable and computes the global-mean for
# masked files.
def global_mean_masked(variable, lats):
    lat_weights = np.cos(np.deg2rad(lats))

    lon_dim_avg = variable.mean(axis=2)
    if np.ma.is_masked(lon_dim_avg):
        variable_global = np.ma.average(lon_dim_avg, axis=1,
                                        weights=lat_weights)
    else:
        variable_global = np.average(lon_dim_avg, axis=1, weights=lat_weights)

    return variable_global


def spatial_mean_bounded(variable, lat, lon, lat_bnds, lon_bnds):
    print('Computing spatial mean. lat={}-{}, lon={}-{}. Points are inclusive.'
          ''.format(*lat_bnds, *lon_bnds))

    [reduced_var,
     reduced_lat,
     reduced_lon] = reduce_to_lat_lon_box(variable, lat, lon,
                                          lat_bnds, lon_bnds)

    avg_over_lat = global_mean_masked(reduced_var, reduced_lat)

    return avg_over_lat


# This functions takes a field reduces it to lat/lon boundaries
def reduce_to_lat_lon_box(field, lat, lon, lat_bnds, lon_bnds):
    lat_lb, lat_ub = lat_bnds
    lon_lb, lon_ub = lon_bnds

    lat_mask = (lat >= lat_lb) & (lat <= lat_ub)
    lon_mask = (lon >= lon_lb) & (lon <= lon_ub)

    lon_compressed = lon[lon_mask]
    lat_compressed = lat[lat_mask]

    field_compressed = np.compress(lon_mask, field, axis=2)
    field_compressed = np.compress(lat_mask, field_compressed, axis=1)

    return field_compressed, lat_compressed, lon_compressed


def remove_spatial_nans(field):

    assert field.ndim > 1

    # Flatten spatial dimension
    ntimes = field.shape[0]
    flat_field = field.reshape(ntimes, -1)

    # Find NaN values in spatial dimension and remove them
    nan_vals = np.isnan(flat_field)
    total_nan_vals = nan_vals.sum(axis=0)
    # No NaNs if sum == 0
    finite_mask = total_nan_vals == 0

    compressed_field = np.compress(finite_mask, flat_field, axis=1)

    return compressed_field, finite_mask



def calculate_pdo(sst, lat, lon):
    """
    Pacific Decadal Oscillation (PDO) index:
    The PDO index is determined by removing the climatological seasonal cycle
    and the global mean (to remove global climate change) from the Pacific SSTs
    north of 20N, then finding the leading EOF.  The PDO index is the first
    principle component.

    References
    ----------
    http://research.jisao.washington.edu/pdo/, Mantua et al., 1997, BAMS

    """
    print("Calculating the Pacific Decadal Oscillation (PDO)")

    # Mask out land.
    sst = ma.masked_invalid(sst)

    # Remove the mean SSTs from the data.
    sst = sst - np.mean(sst, axis=0)

    # Compute the global-mean and remove the global-mean SST from the data.
    sst_globalmean = global_mean_masked(sst, lat)
    sst_anomalies = sst - sst_globalmean[:, None, None]
    sst_anomalies = sst_anomalies.filled(np.nan)

    # Reduce field to all latitudes between 20-66N and 100E-100W
    [sst_for_PDO_NPac,
     lat_NPac,
     lon_NPac] = reduce_to_lat_lon_box(sst_anomalies, lat, lon,
                                       lat_bnds=(20, 66),
                                       lon_bnds=(100, 260))

    # lon_NPac = lon[i_min:i_max+1]
    # lat_NPac = lat[j_min:j_max+1]
    lon_NPac_2D, lat_NPac_2D = np.meshgrid(lon_NPac, lat_NPac)

    # Area weights are equilivent to the cosine of the latitude.
    weights_NPac = np.cos(np.radians(lat_NPac_2D))
    spatial_shape = sst_for_PDO_NPac.shape[1:3]

    [compressed_sst,
     valid_data] = remove_spatial_nans(sst_for_PDO_NPac)

    # Weight compressed field by latitude and calculate EOFs
    wgt_compressed_sst = compressed_sst * weights_NPac.flatten()[valid_data]
    eofs, svals, pcs = svd(wgt_compressed_sst.T, full_matrices=False)

    # Put EOFs back into non-compressed field
    full_space_eof = np.empty_like(valid_data,
                                   dtype=np.float) * np.nan
    full_space_eof[valid_data] = eofs[:, 0]
    eof_1 = full_space_eof.reshape(spatial_shape)
    pc_1 = pcs[0]

    PDO_pattern = np.squeeze(eof_1)
    PDO_index = np.squeeze(pc_1)

    # Make sure that a positive value indicates a cooler northwest Pacific
    loc_sign_check_lat = np.abs(lat_NPac-39).argmin()
    loc_sign_check_lon = np.abs(lon_NPac-168).argmin()
    if PDO_pattern[loc_sign_check_lat, loc_sign_check_lon] > 0:
        PDO_pattern = -1*PDO_pattern
        PDO_index = -1*PDO_index

    # Normalize the PDO index
    PDO_index_normalized = PDO_index/np.std(PDO_index)

    return PDO_pattern, PDO_index_normalized, lat_NPac, lon_NPac


def calculate_pdo_index(pdo_pattern, sst, lat, lon):
    """
    Projects PDO pattern on to data.  Assumes sst field is time x lat x lon.
    """
    if np.ma.is_masked(sst):
        sst = sst.filled(np.nan)

    # Reduce field to all latitudes between 20-66N and 100E-100W
    sst_for_PDO, _, _ = reduce_to_lat_lon_box(sst, lat, lon,
                                              lat_bnds=(20, 66),
                                              lon_bnds=(100, 260))

    # Remove NaN values
    [compressed_sst,
     valid_data] = remove_spatial_nans(sst_for_PDO)

    # Remove NaN value locations in sst field from PDO pattern
    pdo_pattern = pdo_pattern.flatten()[valid_data]

    pdo_index = compressed_sst @ pdo_pattern
    pdo_index = pdo_index / pdo_index.std()

    return pdo_index


def calculate_amo(sst, lat, lon):
    """
    Atlantic Multidecadal Oscillation (AMO) index:
    The AMO index is computed by removing the seasonal cycle from the SST
    data, averaging SSTs anomalies over the north Atlantic (0-60N, 0-80W),
    then removing the 60S-60N mean SST anomalies, to remove the global trend.

    Reference
    ---------
    Trenberth and Shea, Geophys. Res. Lett., 2006

    Notes
    -----
    Different groups have different methods of removing the global temperature signal from the N. Atlantic region.
    In this function we remove global signal by removing the global average SST from 60S - 60N.

    """
    print("Calculating the Atlantic Multidecadal Oscillation (AMO)")

    # Mask out land.
    sst = ma.masked_invalid(sst)

    # Remove the mean SSTs from the data.
    sst = sst - np.mean(sst, axis=0)

    # Reduce field and average to lats from 0-60N and 80W - 0W
    sst_mean_NAtl = spatial_mean_bounded(sst, lat, lon,
                                         lat_bnds=(0, 60),
                                         lon_bnds=(280, 360))

    # Reduce field and average to lats from 60S-60N
    sst_mean_60S_60N = spatial_mean_bounded(sst, lat, lon,
                                            lat_bnds=(-60, 60),
                                            lon_bnds=(0, 360))

    # Compute the AMO index
    AMO_index = sst_mean_NAtl - sst_mean_60S_60N

    return AMO_index


def calculate_nino34(sst, lat, lon):
    """
    Nino3.4 index:
    Nino3.4 is calculating by removing the seasonal cycle from the SST data,
    then averaging over the Nino3.4 region (5S-5N, 170W-120W).

    References
    ---------
    https://www.esrl.noaa.gov/psd/gcos_wgsp/Timeseries/Nino34/
    https://www.ncdc.noaa.gov/teleconnections/enso/indicators/sst.php
    """

    print("Calculating the Nino3.4 index")

    # Mask out land.
    sst = ma.masked_invalid(sst)

    # Remove the mean SSTs from the data.
    sst = sst - np.mean(sst, axis=0)

    # Reduce field and average Nino3.4 region (5S-5N, 170W-120W)
    Nino34 = spatial_mean_bounded(sst, lat, lon, lat_bnds=(-5, 5),
                                  lon_bnds=(190, 240))

    return Nino34


def calculate_soi(psl, lat, lon, years, mean_year_begin=1951,
                  mean_year_end=1980):
    """
    Southern Oscillation (SO) index:
    The SO index is calculated based on the sea level pressure in Tahiti and
    Darwin.  It is calculated according to the equations on the NCDC site
    referenced below.

    Reference
    ---------
    https://www.ncdc.noaa.gov/teleconnections/enso/indicators/soi/
    Tahiti and Darwin lats and lons: Stenseth et al. 2003, Royal Society
    """

    print("Calculating the Southern Oscillation Index (SOI)")

    # Remove the mean PSLs from the data.
    psl = psl - np.mean(psl,axis=0)

    # Sea level pressure at closest model grid cell to Tahiti
    j_Tahiti = np.abs(lat-(-17.55)).argmin()         # Latitude:   17.55S
    i_Tahiti = np.abs(lon-(360-149.617)).argmin()  # Longitude: 149.617W
    print(' Indices for Tahiti.  j: {}, i: {}'.format(j_Tahiti, i_Tahiti))
    psl_Tahiti = psl[:, j_Tahiti, i_Tahiti]
    #
    # Sea level pressure at closest model grid cell to Darwin, Australia
    j_Darwin = np.abs(lat-(-12.467)).argmin()  # Latitude:   12.467S
    i_Darwin = np.abs(lon-130.85).argmin()   # Longitude: 130.85E
    print(' Indices for Darwin.  j: {}, i: {}'.format(j_Darwin, i_Darwin))
    psl_Darwin = psl[:, j_Darwin, i_Darwin]

    # Compute the SOI (based on the equations from NCDC)
    # Mean quantities are calculated over the period 1951-1980 unless otherwise
    # specified.
    print(' Baseline years: {}-{}'.format(mean_year_begin, mean_year_end))
    year_mask = (years >= mean_year_begin) & (years <= mean_year_end)

    psl_Tahiti_anom = psl_Tahiti - psl_Tahiti[year_mask].mean()
    psl_Tahiti_standardized = psl_Tahiti_anom / psl_Tahiti_anom.std()

    psl_Darwin_anom = psl_Darwin - psl_Darwin[year_mask].mean()
    psl_Darwin_standardized = psl_Darwin_anom / psl_Darwin_anom.std()

    SO_index = psl_Tahiti_standardized - psl_Darwin_standardized
    SO_index = SO_index / SO_index.std()

    return SO_index


def calculate_sam(psl, lat, lon, years, mean_year_begin=1951,
                  mean_year_end=1980):
    """
    Southern Annular Mode (SAM) index:
    The SAM index is calculated based on the difference in standardized zonal mean 
    sea level pressure between 40S and 65S. 

    References
    ----------
    Gong and Wang, 1999: Definition of Antarctic Oscillation index. GRL, 26, 459-462
    Marshall, 2003: Trends in the Southern Annular Mode from Observations and 
                    Reanalyses, J. Climate, 16, 4134-4143. 
    """

    print("Calculating the Southern Annular Mode Index (SAM)")

    # Remove the mean PSLs from the data.
    psl = psl - np.mean(psl,axis=0)

    # Sea level pressure at closest model grid cells to 40S
    j_40 = np.abs(lat-(-40.00)).argmin()
    print(' Index for 40S.  j: {}'.format(j_40))
    psl_40S = psl[:, j_40, :]
    #
    # Sea level pressure at closest model grid cells to 65S
    j_65 = np.abs(lat-(-65.00)).argmin()
    print(' Index for 65S.  j: {}'.format(j_65))
    psl_65S = psl[:, j_65, :]
    

    # Compute the SAM index
    # Mean quantities are calculated over the period 1951-1980
    # unless otherwise specified.

    # Zonal mean quantities
    psl_40S_zm = np.mean(psl_40S, axis=1)
    psl_65S_zm = np.mean(psl_65S, axis=1)
    
    print(' Baseline years: {}-{}'.format(mean_year_begin, mean_year_end))
    year_mask = (years >= mean_year_begin) & (years <= mean_year_end)
    psl_40S_zm_anom = psl_40S_zm - psl_40S_zm[year_mask].mean()
    psl_65S_zm_anom = psl_65S_zm - psl_65S_zm[year_mask].mean()
    # standardize
    psl_40S_zm_standardized = psl_40S_zm_anom / psl_40S_zm_anom.std()
    psl_65S_zm_standardized = psl_65S_zm_anom / psl_65S_zm_anom.std()

    SAM_index = psl_40S_zm_standardized - psl_65S_zm_standardized

    return SAM_index


def calculate_ao_zonal_means(psl, lat, lon, years, mean_year_begin=1951,
                             mean_year_end=1980):
    """
    Arctic Oscillation (AO) index:
    The AO index is calculated based on the difference in standardized zonal mean 
    sea level pressure between 35N and 65N. 

    References
    ----------
    Li and Wang, 2003: A modified zonal index and its physical sense.
                       GRL, 30(12), 1632, doi:10.1029/2003GL017441

    """

    print("Calculating the Arctic Oscillation Index (AO)")

    # Remove the mean PSLs from the data.
    psl = psl - np.mean(psl,axis=0)

    # Sea level pressure at closest model grid cells to 35N
    j_35 = np.abs(lat-(35.00)).argmin()
    print(' Index for 35N.  j: {}'.format(j_35))
    psl_35N = psl[:, j_35, :]
    #
    # Sea level pressure at closest model grid cells to 65N
    j_65 = np.abs(lat-(65.00)).argmin()
    print(' Index for 65N.  j: {}'.format(j_65))
    psl_65N = psl[:, j_65, :]
    

    # Compute the AO index
    # Mean quantities are calculated over the period 1951-1980
    # unless otherwise specified.

    # Zonal mean quantities
    psl_35N_zm = np.mean(psl_35N, axis=1)
    psl_65N_zm = np.mean(psl_65N, axis=1)
    
    print(' Baseline years: {}-{}'.format(mean_year_begin, mean_year_end))
    year_mask = (years >= mean_year_begin) & (years <= mean_year_end)
    psl_35N_zm_anom = psl_35N_zm - psl_35N_zm[year_mask].mean()
    psl_65N_zm_anom = psl_65N_zm - psl_65N_zm[year_mask].mean()
    # standardize
    psl_35N_zm_standardized = psl_35N_zm_anom / psl_35N_zm_anom.std()
    psl_65N_zm_standardized = psl_65N_zm_anom / psl_65N_zm_anom.std()

    AO_index = psl_35N_zm_standardized - psl_65N_zm_standardized

    return AO_index


def calculate_nao_stations(psl, lat, lon, years, mean_year_begin=1951,
                           mean_year_end=1980):
    """
    North Atlantic Oscillation (NAO) index:
    The NAO index is here calculated based on the difference in standardized 
    sea level pressure between Lisbon and Reykjavik.

    Reference
    ---------
    Hurrel et al. (2003) in The North Atlantic Oscillation: Climate Significance
    and Environmental Impact, Geophysical Monograph 134, American Geophysical Union.

    http://climatedataguide.ucar.edu/climate-data/hurrell-north-atlantic-oscillation-nao-index-station-based

    """

    print("Calculating the (station-based) North Atlantic Oscillation index (NAO)")

    # Remove the (temporal) mean PSLs from the data.
    psl = psl - np.mean(psl,axis=0)

    # Sea level pressure at closest grid cell to Lisbon, Portugal
    j_Lisbon = np.abs(lat-(38.7223)).argmin()          # Latitude:  38.7223N
    i_Lisbon = np.abs(lon-(360.-9.1393)).argmin()      # Longitude:  9.1393W
    print(' Indices for Lisbon.    j: {}, i: {}'.format(j_Lisbon, i_Lisbon))
    psl_Lisbon = psl[:, j_Lisbon, i_Lisbon]
    
    # Sea level pressure at closest grid cell to Reykjavik, Iceland
    j_Reykjavik = np.abs(lat-(64.1466)).argmin()       # Latitude:  64.1466N
    i_Reykjavik = np.abs(lon-(360.-21.9426)).argmin()  # Longitude: 21.9426W
    print(' Indices for Reykjavik. j: {}, i: {}'.format(j_Reykjavik, i_Reykjavik))
    psl_Reykjavik = psl[:, j_Reykjavik, i_Reykjavik]
    

    # Compute the NAO
    # Mean quantities are calculated over the period 1951-1980 unless otherwise
    # specified.
    print(' Baseline years: {}-{}'.format(mean_year_begin, mean_year_end))
    year_mask = (years >= mean_year_begin) & (years <= mean_year_end)

    psl_Lisbon_anom = psl_Lisbon - psl_Lisbon[year_mask].mean()
    psl_Lisbon_standardized = psl_Lisbon_anom / psl_Lisbon_anom[year_mask].std()
                      
    psl_Reykjavik_anom = psl_Reykjavik - psl_Reykjavik[year_mask].mean()
    psl_Reykjavik_standardized = psl_Reykjavik_anom / psl_Reykjavik_anom[year_mask].std()

    NAO_index = psl_Lisbon_standardized - psl_Reykjavik_standardized

    return NAO_index



# ------------------------------------------------------------------------------
# ------------------------------------------------------------------------------
if __name__ == "__main__":
    main()
